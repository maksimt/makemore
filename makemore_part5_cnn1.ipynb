{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore: part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([205280, 8]) torch.Size([205280])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "# n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n2])     # 90%\n",
    "# Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xdev, Ydev  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdev.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42); # seed rng for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "# original network\n",
    "# n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "# n_hidden = 300 # the number of neurons in the hidden layer of the MLP\n",
    "# model = Sequential([\n",
    "#   Embedding(vocab_size, n_embd),\n",
    "#   FlattenConsecutive(8), Linear(n_embd * 8, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "#   Linear(n_hidden, vocab_size),\n",
    "# ])\n",
    "\n",
    "# hierarchical network\n",
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 120000: 3.2981185913085938\n",
      "   2000/ 120000: 2.013152599334717\n",
      "   4000/ 120000: 1.9650788307189941\n",
      "   6000/ 120000: 2.154043436050415\n",
      "   8000/ 120000: 2.015829563140869\n",
      "  10000/ 120000: 1.864884614944458\n",
      "  12000/ 120000: 2.0411109924316406\n",
      "  14000/ 120000: 1.8795534372329712\n",
      "  16000/ 120000: 1.951696515083313\n",
      "  18000/ 120000: 1.8980633020401\n",
      "  20000/ 120000: 2.0179734230041504\n",
      "  22000/ 120000: 2.090568780899048\n",
      "  24000/ 120000: 1.8399697542190552\n",
      "  26000/ 120000: 1.590334177017212\n",
      "  28000/ 120000: 1.8876601457595825\n",
      "  30000/ 120000: 1.7172987461090088\n",
      "  32000/ 120000: 1.898620367050171\n",
      "  34000/ 120000: 1.845122218132019\n",
      "  36000/ 120000: 1.8062920570373535\n",
      "  38000/ 120000: 1.9629476070404053\n",
      "  40000/ 120000: 1.7521165609359741\n",
      "  42000/ 120000: 1.7274367809295654\n",
      "  44000/ 120000: 1.7106029987335205\n",
      "  46000/ 120000: 1.9965450763702393\n",
      "  48000/ 120000: 1.9239518642425537\n",
      "  50000/ 120000: 1.8556114435195923\n",
      "  52000/ 120000: 1.7668757438659668\n",
      "  54000/ 120000: 1.6470173597335815\n",
      "  56000/ 120000: 1.7105075120925903\n",
      "  58000/ 120000: 1.6804463863372803\n",
      "  60000/ 120000: 1.6649165153503418\n",
      "  62000/ 120000: 1.6610831022262573\n",
      "  64000/ 120000: 1.9423540830612183\n",
      "  66000/ 120000: 1.8941715955734253\n",
      "  68000/ 120000: 1.861930251121521\n",
      "  70000/ 120000: 1.8560395240783691\n",
      "  72000/ 120000: 1.8099644184112549\n",
      "  74000/ 120000: 1.6047492027282715\n",
      "  76000/ 120000: 1.9077253341674805\n",
      "  78000/ 120000: 1.7401024103164673\n",
      "  80000/ 120000: 1.6448463201522827\n",
      "  82000/ 120000: 1.751090407371521\n",
      "  84000/ 120000: 1.6307767629623413\n",
      "  86000/ 120000: 1.7964643239974976\n",
      "  88000/ 120000: 1.839889645576477\n",
      "  90000/ 120000: 1.787061095237732\n",
      "  92000/ 120000: 1.6964739561080933\n",
      "  94000/ 120000: 1.5059311389923096\n",
      "  96000/ 120000: 1.749036192893982\n",
      "  98000/ 120000: 1.660903811454773\n",
      " 100000/ 120000: 1.9604588747024536\n",
      " 102000/ 120000: 1.6978225708007812\n",
      " 104000/ 120000: 1.5559463500976562\n",
      " 106000/ 120000: 1.6884762048721313\n",
      " 108000/ 120000: 1.607592225074768\n",
      " 110000/ 120000: 1.9682523012161255\n",
      " 112000/ 120000: 1.7253364324569702\n",
      " 114000/ 120000: 1.5496562719345093\n",
      " 116000/ 120000: 1.794506549835205\n",
      " 118000/ 120000: 1.731178879737854\n",
      "CPU times: user 17min 29s, sys: 1.17 s, total: 17min 30s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# same optimization as last time\n",
    "max_steps = 120_000\n",
    "batch_size = 128\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update: simple SGD\n",
    "  lr = 0.1 if i < 60_000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 2000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item()}')\n",
    "\n",
    "  lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4de3dc17c0>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1).cpu())  # at each point we plot the average of 1000 minibatch losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.708064317703247\n",
      "val 2.0048654079437256\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    # 'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance log\n",
    "\n",
    "- original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n",
    "- context: 3 -> 8 (22K params): train 1.918, val 2.027\n",
    "- flat -> hierarchical (22K params): train 1.941, val 2.029\n",
    "- fix bug in batchnorm: train 1.912, val 2.022\n",
    "- scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.769, val 1.993\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irianna.\n",
      "dyerren.\n",
      "hamdyn.\n",
      "keilan.\n",
      "damarela.\n",
      "laman.\n",
      "jaydeni.\n",
      "apoola.\n",
      "chagel.\n",
      "marley.\n",
      "luca.\n",
      "ilfany.\n",
      "iana.\n",
      "rustaf.\n",
      "degodon.\n",
      "malou.\n",
      "lovey.\n",
      "banaje.\n",
      "peneya.\n",
      "imyon.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dan.\n",
      "danaleie.\n",
      "danan.\n",
      "danasyah.\n",
      "danayah.\n",
      "danayo.\n",
      "dane.\n",
      "danel.\n",
      "danelle.\n",
      "danelly.\n",
      "danelyn.\n",
      "danes.\n",
      "daneth.\n",
      "daney.\n",
      "daniah.\n",
      "danidee.\n",
      "danie.\n",
      "daniel.\n",
      "danielle.\n",
      "danielo.\n",
      "daniely.\n",
      "danil.\n",
      "danilah.\n",
      "danilie.\n",
      "danis.\n",
      "danish.\n",
      "danit.\n",
      "daniy.\n",
      "daniyah.\n",
      "daniye.\n",
      "dannah.\n",
      "dannie.\n",
      "danniel.\n",
      "dannis.\n",
      "dannon.\n",
      "danny.\n",
      "dannylah.\n",
      "dano.\n",
      "danson.\n",
      "dansun.\n",
      "dansyn.\n",
      "danvek.\n",
      "dany.\n",
      "danyan.\n",
      "danye.\n",
      "danyel.\n",
      "danyelle.\n",
      "danyello.\n",
      "danyiah.\n",
      "danyon.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "prefix = 'dan'\n",
    "letters_must_contain = 'amnd'\n",
    "n_letters = 3\n",
    "\n",
    "suffix_exclude = ['a', 'i']\n",
    "max_length = 8\n",
    "\n",
    "outputs = set([])\n",
    "\n",
    "while len(outputs) < 50:\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    if prefix:\n",
    "        for i, c in enumerate(prefix):\n",
    "            \n",
    "            context[block_size-len(prefix)+i] = stoi[c]\n",
    "            out.append(stoi[c])\n",
    "    while True:\n",
    "        logits = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        # shift the context window and track the samples\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "            \n",
    "    name = ''.join(itos[i] for i in out)\n",
    "    if name[-2] in suffix_exclude:\n",
    "        continue\n",
    "    if len(name) - 1 > max_length:\n",
    "        continue\n",
    "    \n",
    "    n_letters_this_name = 0\n",
    "    for l in set(letters_must_contain):\n",
    "        if l in name:\n",
    "            n_letters_this_name += 1\n",
    "            \n",
    "    if n_letters_this_name >= n_letters or not letters_must_contain:\n",
    "        outputs.add(name)\n",
    "    \n",
    "print(*sorted(outputs), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next time:\n",
    "Why convolutions? Brief preview/hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[7:15], Ytr[7:15]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward a single example:\n",
    "logits = model(Xtr[[7]])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 27])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward all of them\n",
    "logits = torch.zeros(8, 27)\n",
    "for i in range(8):\n",
    "  logits[i] = model(Xtr[[7+i]])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution is a \"for loop\"\n",
    "# allows us to forward Linear layers efficiently over space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
